{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Reminder: This üìò `Python` notebook can be run from VS Code with [these prerequisites](../PREREQS.md)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use this notebook: \n",
    "\n",
    "* Just read the text and scroll along until you run into code blocks.\n",
    "* Code blocks have computer code inside them ‚Äî hover over the block and you can run the code.\n",
    "* Run the code by hitting the ‚ñ∂Ô∏è \"play\" button to the left. If the code runs you'll see a ‚úîÔ∏è. If not, you'll get a ‚ùå.\n",
    "* The output and status of the code block will appear just below itself ‚Äî you need to scroll down further to see it.\n",
    "* Sometimes a code block will ask you for input in a hard-to-notice dialog box üëÜ at the top of your notebook window. \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe V: üçã Connectors w/ Bing\n",
    "## üßë‚Äçüç≥ Cook using fresher context with live data from APIs\n",
    "\n",
    "## Step 1: Instantiate a üî• kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install semantic-kernel==0.3.3.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextCompletion, OpenAITextCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Integrate live data with the Bing Web Search API üçã connector\n",
    "\n",
    "To get a Bing Web Search API key visit [this resource](https://www.microsoft.com/en-us/bing/apis/bing-web-search-api) to start. Once you have that in hand, you can now grab live search information to get added to the context of your choice. For example, we can find out what's the tallest building in Europe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The tallest building in New York is One World Trade Center, which rises 1,776 feet (541 m). [2] [3] [4] The 104-story [A] skyscraper also stands as the tallest building in the United States, the tallest building in the Western Hemisphere, and the seventh-tallest building in the world.']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel.connectors.search_engine import BingConnector\n",
    "from semantic_kernel.core_skills import WebSearchEngineSkill\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "BING_API_KEY = \"75037f51137a43a8bacb6ba35a7203a3\"\n",
    "connector = BingConnector(api_key=os.getenv(\"BING_API_KEY\"))\n",
    "web_skill = kernel.import_skill(WebSearchEngineSkill(connector), \"WebSearch\")\n",
    "\n",
    "search_async = web_skill[\"searchAsync\"]\n",
    "\n",
    "bing_result = await search_async.invoke_async(\"What's the tallest building in NYC?\")\n",
    "print(bing_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚úÖ Keep in mind that getting a Bing Web Search API key will require you to have a fresh FREE Azure account, or else a paid Azure account with active billing credentials.\n",
    "\n",
    "> ü§î **Get `\"Error: Response status code does not indicate success: 401 (PermissionDenied).\"` message?** This could happen if you just provisioned a Bing Web Search API. Wait a few minutes and try again. \n",
    "\n",
    "> üò± **Get a different error message?** go to https://aka.ms/sk/discord where we have realtime support available to troubleshoot your problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Combine existing ü•ë memories with fresh üçã data\n",
    "\n",
    "So we take our memories to the next level by providing it \"live\" memories that are delivered via a connector. It's a terrific combination of both _timeless_ information and _timely_ information. We feed the output of the `SearchAsync` function into a custom-crafted inline semantic function to tell a short story while including a few \"facts\" as inline ü•ë memories, like:\n",
    "\n",
    "1. I'm tall-ish: about 5ft 11in\n",
    "2. I like sushi ‚Äî but not the kind with uni\n",
    "\n",
    "And we'll add a fresh memory that we grab from a Bing üçã connector to brag that we've been to `the tallest building in NYC` by adding a 3rd fact of:\n",
    "\n",
    "3. I've been to <the tallest building in NYC>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm a tall-ish person who loves sushi, but not the kind with uni. I've been to the tallest building in New York, One World Trade Center, which stands at 1,776 feet. It's the tallest building in the United States, the tallest building in the Western Hemisphere, and the seventh-tallest building in the world. I'm always looking for new and exciting places to explore, and I'm always up for a challenge.\n"
     ]
    }
   ],
   "source": [
    "skprompt = \"\"\"\n",
    "    These are facts about me:\n",
    "    1. I'm tall-ish: about 5ft 11in\n",
    "    2. I like sushi ‚Äî but not the kind with uni\n",
    "    3. I've been to {{$input}}\n",
    "    Here is a short story under 100 words about me:\n",
    "\"\"\"\n",
    "my_inline_semantic_function = kernel.create_semantic_function(skprompt, max_tokens=200, temperature=0.1, top_p=0.1)\n",
    "\n",
    "result = await kernel.run_async(search_async, my_inline_semantic_function, input_str=\"What's the tallest building in NYC?\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see how it's possible to use Semantic Kernel in a variety of ways ‚Äî from designing prompts, expanding a prompt's context with memories, and now drawing live data into an LLM AI's processing capability.\n",
    "\n",
    "## Step 4: Let's go one step further and add some extra seasoning with the `SummarizeSkill.Notegen` üßÇ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal Info\n",
      "- Tall-ish\n",
      "- Likes sushi, not uni\n",
      "- Visited One World Trade Center (1,776 ft)\n",
      "- Always exploring, up for challenge\n"
     ]
    }
   ],
   "source": [
    "skills_directory = \"./skills/\"\n",
    "mySkill = kernel.import_semantic_skill_from_directory(skills_directory, \"SummarizeSkill\")\n",
    "\n",
    "result = await kernel.run_async(\n",
    "    search_async,\n",
    "    my_inline_semantic_function,\n",
    "    mySkill[\"Notegen\"],\n",
    "    input_str=\"What's the tallest building in NYC?\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look closely at the code, what we did is make a \"chain\" of functions. We'll be doing that in our next recipe section in the context of a well-known process for innovation called \"Design Thinking.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚è≠Ô∏è Next Steps\n",
    "\n",
    "Run through more advanced examples in the notebooks that are available in our GitHub repo at [https://aka.ms/sk/repo](https://aka.ms/sk/repo).\n",
    "\n",
    "[Design thinking with üî• kernel is up next!](../e6-design-chain/notebook.ipynb)\n",
    "\n",
    "Or stay a longer while and ask Bing to added new information from the Internet to fortify your LLM AI magic. And you can also try different functions within the `SummarizeSkill` to see different outputs in Step 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
